{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba157a6b-1473-49f3-b018-a1500fb4831e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T06:47:34.263042Z",
     "iopub.status.busy": "2025-07-03T06:47:34.262850Z",
     "iopub.status.idle": "2025-07-03T06:47:34.268380Z",
     "shell.execute_reply": "2025-07-03T06:47:34.267902Z",
     "shell.execute_reply.started": "2025-07-03T06:47:34.263026Z"
    },
    "id": "ba157a6b-1473-49f3-b018-a1500fb4831e"
   },
   "source": [
    "<font size=\"5\">**[Object Detection](https://en.wikipedia.org/wiki/Object_detection) con YOLO**.<br>\n",
    "\n",
    "> (c) 2025 Antonio Piemontese\n",
    "\n",
    "# Un sistema di video-sorveglianza\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4709ddef-77f8-4dbd-9efb-cffb4a4dcf90",
   "metadata": {},
   "source": [
    "Ecco come costruire **un sistema di videosorveglianza** intelligente e personalizzato per la casa o per il condominio.<br>\n",
    "Il notebook mostra come installare gratuitamente un sistema di videosorveglianza capace di identificare e contare oggetti e persone in tempo reale, utilizzando solo una webcam e un computer. Nessun costo aggiuntivo per hardware complesso o software costosi.<br>\n",
    "Basta qualche passo, Python e YOLO11 Ultralitycs per trasformare immediatamente la webcam in una sofisticata telecamera di sorveglianza professionale con riconoscimento degli oggetti.\n",
    "\n",
    "**Cosa si può fare con questo sistema di videosorveglianza?**<br>\n",
    "Le applicazioni sono moltissime:\n",
    "- sorveglianza esterna e interna: ideale per casa, condominio o attività commerciale.\n",
    "- rilevamento intelligente: ricevi notifiche immediate se delle persone o animali entrano nell’area sorvegliata.\n",
    "- automazioni avanzate: integra facilmente l’invio automatico di notifiche email o chat \n",
    "\n",
    "**Requisiti**:\n",
    "- una webcam collegata al computer\n",
    "- Python installato\n",
    "- la libreria PyTorch per gestire il deep learning sul processore CPU\n",
    "- il software YOLO11 di Ultralytics, l’ultimo standard per il riconoscimento degli oggetti con intelligenza artificiale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5HZ9WWe-E-vN",
   "metadata": {
    "id": "5HZ9WWe-E-vN"
   },
   "source": [
    "---\n",
    "Il notebook è  configurato in modo da funzionare in Jupyter Notebook oppure in Google Colab. L'elaborazione di grandi video è accelerata dalla disponibilità di una GPU.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iN2sNoPa33MN",
   "metadata": {
    "id": "iN2sNoPa33MN"
   },
   "source": [
    "Come prima cosa, quindi, **rileviamo l'ambiente di esecuzione del notebook** (Jupyter oppure Google Colab: la cella imposta una variabile booleana `IN_COLAB` che sarà testata da alcune celle del notebook (in particolare quelle di visualizzazione di immagini) per personalizzarne il comportamento a seconda dell'ambiente di esecuzione dell'ambiente rilevato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "E5unK3Df3741",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:35:36.393352Z",
     "iopub.status.busy": "2025-10-09T16:35:36.393161Z",
     "iopub.status.idle": "2025-10-09T16:35:36.398817Z",
     "shell.execute_reply": "2025-10-09T16:35:36.398311Z",
     "shell.execute_reply.started": "2025-10-09T16:35:36.393338Z"
    },
    "id": "E5unK3Df3741",
    "outputId": "d967b6e2-08e9-44e0-d15b-f85bc17bcbee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siamo in Colab: False\n"
     ]
    }
   ],
   "source": [
    "# impostazione del TOGGLE BINARIO:\n",
    "try:\n",
    "    import google.colab                      # package disponibile SOLO in Google Colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(\"Siamo in Colab:\", IN_COLAB)\n",
    "\n",
    "\n",
    "# IMPORT dei package necessari per la VISUALIZZAZIONE delle IMMAGINI (necessari sia in JN che in Colab):\n",
    "from IPython.display import Image, display   # import dei package di incorporamento e visualizzazione immagine (una tantum)\n",
    "                                             # Image e display sono entrambi necessari a Jupyter Notebook\n",
    "                                             # Google Colab utilizza solo Image\n",
    "import os                                    # necessario a Google Colab per vedere da una cella codice\n",
    "                                             # i contenuti del 'content'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XFvFXIzE4UL_",
   "metadata": {
    "id": "XFvFXIzE4UL_"
   },
   "source": [
    "Le immagini utilizzate in questo notebook, da caricare nella memoria di sessione, sono:\n",
    "- `modelli_YOLOv8.png`\n",
    "- `modelli_YOLOv8_costi.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad23acb-78cf-4efe-8f25-988e3731d1a5",
   "metadata": {
    "id": "0ad23acb-78cf-4efe-8f25-988e3731d1a5"
   },
   "source": [
    "# Introduzione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97770e49-ce63-4c72-80fe-09a1a0b9bb76",
   "metadata": {
    "id": "97770e49-ce63-4c72-80fe-09a1a0b9bb76"
   },
   "source": [
    "Usiamo `YOLO` v8 (di Ultralytics). Vedi la [voce Wikipedia su YOLO](https://en.wikipedia.org/wiki/You_Only_Look_Once).<br>\n",
    "Vedi il [sito di Ultralytics](https://www.ultralytics.com/) e la [pagina di Ultralytics sulla *object detection*](https://docs.ultralytics.com/tasks/detect/).\n",
    "YOLO è un **approccio**, **una tecnologia**; Ultralytics è una **software house** che ha implementato lo standard YOLO (che evolve di continuo: v8 del 2023, v9 del 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f758c4-70ab-41fd-8f26-e2ba3ab2edb3",
   "metadata": {
    "id": "98f758c4-70ab-41fd-8f26-e2ba3ab2edb3"
   },
   "source": [
    "YOLO (You Only Look Once) è una famiglia di modelli di **deep learning (reti neurali profonde) per object detection** (in particolare [reti CNN](https://it.wikipedia.org/wiki/Rete_neurale_convoluzionale)) **in tempo reale**, e nel corso degli anni si è evoluta attraverso molte versioni, ciascuna con **tecnologie diverse**. Riassumiamo le **tecnologie chiave** usate in generale, poi focalizziamoci  sulle versioni più recenti (come YOLOv5–**v8** e YOLO-NAS).\n",
    "\n",
    "---\n",
    "\n",
    "In generale, YOLO usa:\n",
    "\n",
    "1. **Reti Neurali Convoluzionali (CNN)**\n",
    "\n",
    "È la base di tutti i modelli YOLO. Le CNN sono ideali per analizzare immagini (e quindi anche video) grazie alla loro capacità di estrarre automaticamente feature spaziali.\n",
    "\n",
    "2. **Single-Shot Detection**\n",
    "\n",
    "YOLO fa **una sola previsione (*prediction*) per immagine** (\"you only look once\"), dividendo l'immagine in griglie e predicendo, per ogni cella, le **bounding box**, le **classi** e la **confidenza** della classificazione.\n",
    "\n",
    "3. **Anchor Boxes**\n",
    "\n",
    "Usate per migliorare la predizione di oggetti con proporzioni diverse (es. un autobus vs un semaforo).\n",
    "\n",
    "---\n",
    "\n",
    "**Tecnologie specifiche per versione**:\n",
    "\n",
    "YOLOv1–v3 (Darknet)\n",
    "\n",
    "* Scritto in C e CUDA (framework chiamato **Darknet**)\n",
    "* Usa CNN standard (es. Darknet-19, Darknet-53)\n",
    "* Più veloce, meno accurato rispetto a modelli moderni\n",
    "\n",
    "YOLOv4 (AlexeyAB fork)\n",
    "\n",
    "* Aggiunge tecniche di **training bag of freebies/tricks**\n",
    "* Include **Mish activation**, **CSPNet**, **Squeeze-and-Excitation**\n",
    "\n",
    "YOLOv5 (Ultralytics, in PyTorch) - **la svolta**\n",
    "\n",
    "* Codice 100% in **Python + PyTorch** (la libreria di deep learning più diffusa, completamente open-source, realizzata da Meta)\n",
    "* Modularità, facilità d’uso, supporto a GPU/CPU\n",
    "* Augmentazioni: Mosaic, MixUp\n",
    "* Varianti da YOLOv5s (small) a YOLOv5x (extra large)\n",
    "\n",
    "YOLOv6 / v7 / v8\n",
    "\n",
    "* YOLOv6: orientato alla produzione, TensorRT-friendly\n",
    "* YOLOv7: supporto per **task multipli** (detection, pose, segmentation)\n",
    "* **YOLOv8 (Ultralytics)**: riscrittura più pulita, supporta anche:\n",
    "\n",
    "  * Object Detection\n",
    "  * Semantic Segmentation\n",
    "  * Instance Segmentation\n",
    "  * Pose Estimation\n",
    "  * Classificazione\n",
    "\n",
    "È **quella che useremo**: il modello infatti è in `.pt` e usi `YOLO(...)`.\n",
    "\n",
    "**YOLOv9** è stato rilasciato nel 2024 e porta importanti miglioramenti.\n",
    "\n",
    "YOLO-NAS (Neural Architecture Search)\n",
    "\n",
    "* Proposto da **Deci AI**\n",
    "* Basato su **NAS**: la rete è \"ottimizzata automaticamente\"\n",
    "* Più accurato e veloce rispetto alle versioni precedenti, con attenzione alle prestazioni su dispositivi edge\n",
    "\n",
    "---\n",
    "\n",
    "Backend tecnologici recenti\n",
    "\n",
    "| Tecnologia          | Dettagli                                  |\n",
    "| ------------------- | ----------------------------------------- |\n",
    "| **PyTorch**         | usato da YOLOv5, YOLOv8 (Ultralytics)     |\n",
    "| **ONNX / TensorRT** | esportazione per inferenza ottimizzata    |\n",
    "| **OpenCV**          | usato per video processing e I/O immagini |\n",
    "| **TorchScript**     | usato per ottimizzare i modelli PyTorch   |\n",
    "| **CUDA / cuDNN**    | se usi GPU NVIDIA                         |\n",
    "\n",
    "---\n",
    "\n",
    "YOLO è veloce perché…\n",
    "\n",
    "* Tutta la detection avviene **in una sola passata** (vs modelli two-stage come Faster R-CNN)\n",
    "* È ottimizzato per inferenza real-time, anche su hardware non super potente\n",
    "\n",
    "NB. Nel mondo del Deep Learning, per \"inferenza\" si intende l'utilizzo di una rete pre-allenata.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec8c52-6aa3-400a-8e6d-e77ca465e4dc",
   "metadata": {
    "id": "fcec8c52-6aa3-400a-8e6d-e77ca465e4dc"
   },
   "source": [
    "# Installazioni per Jupyter Notebook\n",
    "Da un prompt anaconda, attivo sull'ambiente virtuale di vostra scelta (comunque lo stesso del kernel di Jupyter Notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d3dc5-ec30-4e69-be60-2538d9cac63d",
   "metadata": {
    "id": "9d7d3dc5-ec30-4e69-be60-2538d9cac63d"
   },
   "source": [
    "Per sicurezza, come prima cosa, disinstalliamo PyTorch, la libreria di Deep Learning open-source di Meta. Vedi [qui](https://pytorch.org/).\n",
    "\n",
    "PyTorch è il porting su Python della libreria Torch. PyTorch ha oggi più successo di Torch (l'allievo ha superato il maestro). Gli sviluppatori di Meta, in omaggio a Torch, hanno chiamato la libreria PyTorch `Torch`. `PyTorch` è solo il termine conevenzionale di riferimento, ma **la installazione e la import la si fa di torch**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51538334-8e59-436e-aded-64e64e0f873b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T10:01:11.364984Z",
     "iopub.status.busy": "2025-10-09T10:01:11.364695Z",
     "iopub.status.idle": "2025-10-09T10:01:49.382375Z",
     "shell.execute_reply": "2025-10-09T10:01:49.381975Z",
     "shell.execute_reply.started": "2025-10-09T10:01:11.364968Z"
    },
    "id": "51538334-8e59-436e-aded-64e64e0f873b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719fb0ae-b2d2-4952-94da-b8f7bd0ff88a",
   "metadata": {
    "id": "719fb0ae-b2d2-4952-94da-b8f7bd0ff88a"
   },
   "source": [
    "Installiamo `PyTorch` **per CPU**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190986e7-8ab4-4475-9584-78523fe943ef",
   "metadata": {
    "id": "190986e7-8ab4-4475-9584-78523fe943ef"
   },
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f667157a-9fb4-407d-9b75-e5389d4b64c8",
   "metadata": {
    "id": "f667157a-9fb4-407d-9b75-e5389d4b64c8"
   },
   "source": [
    "L'output atteso (corretto) è il seguente:<br>\n",
    "`Successfully installed torch-2.7.1+cpu torchaudio-2.7.1+cpu torchvision-0.22.1+cpu`<br>\n",
    "Ha installato l'ultima versione dei 3 package **per CPU**, come chiesto da noi.\n",
    "\n",
    "La descrizione del package [PyTorch](https://pypi.org/project/pytorch/) come sempre è ricavabile consultanno l'indice ufficiale di tutti i package python: [**PyPI**](https://pypi.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309471ef-fb83-4881-9a96-2d8574336f06",
   "metadata": {
    "id": "309471ef-fb83-4881-9a96-2d8574336f06"
   },
   "source": [
    "Installazione di YOLO (nella implementazione della software house **ultralytics**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea96881d-6d0f-4280-907b-f378295fdc23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea96881d-6d0f-4280-907b-f378295fdc23",
    "outputId": "3c9e4004-b59f-4d6d-dc74-e2e33888fa89"
   },
   "outputs": [],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc75ea30-9396-4fd1-895f-d84c5f113d87",
   "metadata": {
    "id": "dc75ea30-9396-4fd1-895f-d84c5f113d87"
   },
   "source": [
    "Invece, il seguente comando:\n",
    "\n",
    "```python\n",
    "pip install -U ultralytics\n",
    "```\n",
    "aggiorna all'ultima versione disponibile, anche se ultralytics è già installato. Cioè:<br>\n",
    "- `pip install ultralytics` → installa solo se non è già presente\n",
    "- `pip install -U ultralytics` → forza l’aggiornamento all’ultima versione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OpgNOy0L67eV",
   "metadata": {
    "id": "OpgNOy0L67eV"
   },
   "source": [
    "# Installazioni per Google Colab\n",
    "*PyTorch* è già installato nella sessione di Google Colab.\n",
    "\n",
    "Esistono differenti versioni di PyTorch, a seconda del tipo di run-time (CPU, GPU, TPU, ecc), Google Colab rende disponibile la versione di PyTorch adatta al run-time che abbiamo scelto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "uP4_Fd-T6-pN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:35:46.298629Z",
     "iopub.status.busy": "2025-10-09T16:35:46.298379Z",
     "iopub.status.idle": "2025-10-09T16:35:49.032874Z",
     "shell.execute_reply": "2025-10-09T16:35:49.032335Z",
     "shell.execute_reply.started": "2025-10-09T16:35:46.298612Z"
    },
    "id": "uP4_Fd-T6-pN",
    "outputId": "ea58e03c-aa83-4dd3-b68e-6e52a50a1442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iYHawE1n7KgF",
   "metadata": {
    "id": "iYHawE1n7KgF"
   },
   "source": [
    "Se il runtime scelto è di tipo 'GPU', `torch.cuda` è disponibile e la print dirà \"True\".\n",
    "\n",
    "Per le TPU su Colab, per PyTorch si deve usare la libreria `torch_xla`, es:\n",
    "\n",
    "```python\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "device = xm.xla_device()\n",
    "```\n",
    "\n",
    "Ma attenzione: è una configurazione un po’ più avanzata e non tutte le librerie sono compatibili. In generale, **se si sta usando PyTorch standard, meglio usare il runtime GPU**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_zxpdgFI9JCV",
   "metadata": {
    "id": "_zxpdgFI9JCV"
   },
   "source": [
    "La libreria `Ultralytics` deve invece esere installata , come fatto in Jupyter Notebook. Occorrono circa **3 minuti**.<br>\n",
    "Alcune dipendenze risultano già presenti, ma l'installazione è indispensabile altrimenti la successiva *import* della libreria non funzionerà."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XzzWxPpM9RsM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzzWxPpM9RsM",
    "outputId": "9569e15e-426c-46ad-c702-6d6d970ca319"
   },
   "outputs": [],
   "source": [
    "!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e576d8a-b3f9-4d8d-b12d-c331d79f0689",
   "metadata": {
    "id": "7e576d8a-b3f9-4d8d-b12d-c331d79f0689"
   },
   "source": [
    "# YOLO vs Ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20151b-6736-47b8-a837-baf7ea9e5572",
   "metadata": {
    "id": "1e20151b-6736-47b8-a837-baf7ea9e5572"
   },
   "source": [
    "---\n",
    "La confusione tra **YOLO** e **Ultralytics** è comune, ma i due termini indicano **cose diverse**.\n",
    "\n",
    "---\n",
    "\n",
    "In breve:\n",
    "\n",
    "| Termine         | Cos'è                                                                               |\n",
    "| --------------- | ----------------------------------------------------------------------------------- |\n",
    "| **YOLO**        | Una *famiglia di modelli* per object detection                                      |\n",
    "| **Ultralytics** | Un’**azienda** + una **libreria Python** open source che implementa YOLO in PyTorch |\n",
    "\n",
    "---\n",
    "\n",
    "Approfondiamo:\n",
    "\n",
    "**YOLO (You Only Look Once)**\n",
    "\n",
    "* È un **approccio di object detection one-shot**: elabora l’intera immagine in una sola passata della rete.\n",
    "* Nato nel 2015 da **Joseph Redmon**, con YOLOv1.\n",
    "* Si è evoluto nel tempo in:\n",
    "\n",
    "  * YOLOv1 → YOLOv2 → YOLOv3 (basati su **Darknet**, framework in C/CUDA)\n",
    "  * Fork come YOLOv4 (Alexey Bochkovskiy), YOLOv5, YOLOv6, YOLOv7, YOLOv8, YOLO-NAS...\n",
    "* YOLO è oggi più un **\"paradigma\" di detection veloce e realtime** che un singolo modello. E' uno standard?!\n",
    "\n",
    "---\n",
    "\n",
    "**Ultralytics**\n",
    "\n",
    "* È una **software house** che:\n",
    "\n",
    "  * Ha sviluppato **YOLOv5** (2020) e poi **YOLOv8** (2023)\n",
    "  * Ha riscritto YOLO interamente in **PyTorch**\n",
    "  * Ha creato la libreria `ultralytics` che semplifica tutto: training, inferenza (l'utilizzo), export (dei risultati).\n",
    "\n",
    "* Il comando `from ultralytics import YOLO` fa parte proprio di questa libreria.\n",
    "\n",
    "> **YOLOv8** è la penultima versione del modello YOLO sviluppata da Ultralytics (rilasciata a gennaio 2023).<br>\n",
    "> La libreria ultralytics che contiene YOLOv8 ha invece una numerazione delle versioni software separata, ed è arrivata alla versione **v11.x**.\n",
    "Vedi [questa pagina](https://github.com/ultralytics/assets/releases) di Ultralytics per chiarimenti.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d05fcba5-fe33-4eca-ab4c-f6176793ce29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T16:35:56.230847Z",
     "iopub.status.busy": "2025-10-09T16:35:56.230661Z",
     "iopub.status.idle": "2025-10-09T16:35:56.599261Z",
     "shell.execute_reply": "2025-10-09T16:35:56.598670Z",
     "shell.execute_reply.started": "2025-10-09T16:35:56.230833Z"
    },
    "id": "d05fcba5-fe33-4eca-ab4c-f6176793ce29"
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO   # 2-3 secondi di esecuzione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a64137-df05-4e7f-a943-ddd29cde7239",
   "metadata": {
    "id": "21a64137-df05-4e7f-a943-ddd29cde7239"
   },
   "source": [
    "# I modelli di YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae66e1-6c89-4e43-8028-fc159096c602",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T19:16:35.272711Z",
     "iopub.status.busy": "2025-07-03T19:16:35.272425Z",
     "iopub.status.idle": "2025-07-03T19:16:35.277184Z",
     "shell.execute_reply": "2025-07-03T19:16:35.276613Z",
     "shell.execute_reply.started": "2025-07-03T19:16:35.272695Z"
    },
    "id": "34ae66e1-6c89-4e43-8028-fc159096c602"
   },
   "source": [
    "YOLOv8 mette a disposizione 5 modelli di riconoscimento oggetti (gratuiti), qui riferiti alla v11 di Ultralytics:\n",
    "- `yolo11n`: la versione **nano**, quella meno precisa e che richiede meno risorse\n",
    "- `yolo11s`: la versione **small**\n",
    "- `yolo11m`: la versione **media**\n",
    "- `yolo11l`: la versione **large**\n",
    "- `yolo11x`: la versione **extra-large**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "WoG9W3SN5LA-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 389
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:35:58.265100Z",
     "iopub.status.busy": "2025-10-09T16:35:58.264912Z",
     "iopub.status.idle": "2025-10-09T16:35:58.270838Z",
     "shell.execute_reply": "2025-10-09T16:35:58.270319Z",
     "shell.execute_reply.started": "2025-10-09T16:35:58.265087Z"
    },
    "id": "WoG9W3SN5LA-",
    "outputId": "947e9863-c03b-4a53-fe48-262383b4bbda"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Image('modelli_YOLOv8.png') if IN_COLAB else display(Image(filename='modelli_YOLOv8.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "EIB95dcN5pct",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:35:59.264997Z",
     "iopub.status.busy": "2025-10-09T16:35:59.264811Z",
     "iopub.status.idle": "2025-10-09T16:35:59.278934Z",
     "shell.execute_reply": "2025-10-09T16:35:59.278589Z",
     "shell.execute_reply.started": "2025-10-09T16:35:59.264984Z"
    },
    "id": "EIB95dcN5pct",
    "outputId": "84ffa9e0-2c1a-4698-99fd-bccaff7408ac"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Image('modelli_YOLOv8_costi.png') if IN_COLAB else display(Image(filename='modelli_YOLOv8_costi.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252fb022-2baa-424c-b512-1bb8dc1e628d",
   "metadata": {},
   "source": [
    "# Il webhook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c6f085-853e-4c7f-b1a2-94dfcc9786f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:00.796967Z",
     "iopub.status.busy": "2025-10-09T16:36:00.796782Z",
     "iopub.status.idle": "2025-10-09T16:36:00.800573Z",
     "shell.execute_reply": "2025-10-09T16:36:00.800138Z",
     "shell.execute_reply.started": "2025-10-09T16:36:00.796954Z"
    }
   },
   "outputs": [],
   "source": [
    "URL_WEBHOOK = \"https://hooks.zapier.com/hooks/catch/23724713/u3l6nas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc81e8d-084d-44b5-b0e3-de0780fadce1",
   "metadata": {},
   "source": [
    "# Yolo v26\n",
    "\n",
    "[Qui](https://www.tiktok.com/@brainlink_project/video/7554513155913944342?_r=1&_t=ZN-90HQ0cLFNNG) un video di [***brainlink***](https://www.youtube.com/channel/UCyKvp4laNQfYUql3zmiMMhg/about) - una ottima academy sulla AI e ML - sull'**ultima versione di Yolo, la v26**, uscita ad inizio ottobre 2025."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf340149-8b87-4caa-85bc-a38fae25ecf8",
   "metadata": {
    "id": "bf340149-8b87-4caa-85bc-a38fae25ecf8"
   },
   "source": [
    "# Il nostro modello (per questo notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VPJ65SW2CYFg",
   "metadata": {
    "id": "VPJ65SW2CYFg"
   },
   "source": [
    "Scarichiamo il modello YOLO (l'ultimo) con la funzione `YOLO` prima importata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb11edcf-a11c-4658-bc26-f4582e31aced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:02.885867Z",
     "iopub.status.busy": "2025-10-09T16:36:02.885683Z",
     "iopub.status.idle": "2025-10-09T16:36:03.004655Z",
     "shell.execute_reply": "2025-10-09T16:36:03.004226Z",
     "shell.execute_reply.started": "2025-10-09T16:36:02.885854Z"
    },
    "id": "eb11edcf-a11c-4658-bc26-f4582e31aced"
   },
   "outputs": [],
   "source": [
    "model = YOLO(\"yolo11m.pt\")    # il modello YOLO da usare per il riconoscimento degli oggetti.\n",
    "                              # lo scarica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547499ed-5e97-497f-ae89-b70787a51357",
   "metadata": {
    "id": "547499ed-5e97-497f-ae89-b70787a51357"
   },
   "source": [
    "> `.pt` → è un modello PyTorch salvato, compatibile con ultralytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522cc6c-5b65-4f5d-95b3-d48e79ce6e80",
   "metadata": {
    "id": "2522cc6c-5b65-4f5d-95b3-d48e79ce6e80"
   },
   "source": [
    "Nell'oggetto `model` abbiamo il modello **PREALLENATO ISTANZIATO**.\n",
    "\n",
    "Vediamo la **classe** dell'oggetto e poi **l'architettura** del modello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef4f9364-85df-49d2-bcc7-145d346e815f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:05.658305Z",
     "iopub.status.busy": "2025-10-09T16:36:05.658112Z",
     "iopub.status.idle": "2025-10-09T16:36:05.662569Z",
     "shell.execute_reply": "2025-10-09T16:36:05.662198Z",
     "shell.execute_reply.started": "2025-10-09T16:36:05.658292Z"
    },
    "id": "ef4f9364-85df-49d2-bcc7-145d346e815f",
    "outputId": "53399620-33c5-4925-d074-bbac9cbfab2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.models.yolo.model.YOLO"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8776323a-a792-45a7-be12-61a49a6961f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:06.146514Z",
     "iopub.status.busy": "2025-10-09T16:36:06.146264Z",
     "iopub.status.idle": "2025-10-09T16:36:06.154358Z",
     "shell.execute_reply": "2025-10-09T16:36:06.153927Z",
     "shell.execute_reply.started": "2025-10-09T16:36:06.146497Z"
    },
    "id": "8776323a-a792-45a7-be12-61a49a6961f8",
    "outputId": "b28272c7-4f41-4083-f21d-e268a7eb3e84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetectionModel(\n",
       "  (model): Sequential(\n",
       "    (0): Conv(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Conv(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (2): C3k2(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): C3k(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (4): C3k2(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): C3k(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (6): C3k2(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): C3k(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (8): C3k2(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): C3k(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): SPPF(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (10): C2PSA(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): Sequential(\n",
       "        (0): PSABlock(\n",
       "          (attn): Attention(\n",
       "            (qkv): Conv(\n",
       "              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (proj): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (pe): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "          (ffn): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (12): Concat()\n",
       "    (13): C3k2(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): C3k(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (15): Concat()\n",
       "    (16): C3k2(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): C3k(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (17): Conv(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (18): Concat()\n",
       "    (19): C3k2(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): C3k(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (20): Conv(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "      (act): SiLU(inplace=True)\n",
       "    )\n",
       "    (21): Concat()\n",
       "    (22): C3k2(\n",
       "      (cv1): Conv(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (cv2): Conv(\n",
       "        (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (m): ModuleList(\n",
       "        (0): C3k(\n",
       "          (cv1): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv2): Conv(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (cv3): Conv(\n",
       "            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (m): Sequential(\n",
       "            (0): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Bottleneck(\n",
       "              (cv1): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (cv2): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (23): Detect(\n",
       "      (cv2): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x Sequential(\n",
       "          (0): Conv(\n",
       "            (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv(\n",
       "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (cv3): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): DWConv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): DWConv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1-2): 2 x Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): DWConv(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "              (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): DWConv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "          (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (dfl): DFL(\n",
       "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model    # la sequenza dei layer della CNN; per noi in questo corso può rimanere non comprensibile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285fd5fb-f378-41e9-b236-4902adcb5a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T20:30:31.576297Z",
     "iopub.status.busy": "2025-07-03T20:30:31.575946Z",
     "iopub.status.idle": "2025-07-03T20:30:31.580403Z",
     "shell.execute_reply": "2025-07-03T20:30:31.579857Z",
     "shell.execute_reply.started": "2025-07-03T20:30:31.576281Z"
    },
    "id": "285fd5fb-f378-41e9-b236-4902adcb5a9c"
   },
   "source": [
    "Sintesi dei layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db5aea5d-c673-48d6-876d-823f2e2e94d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:07.987257Z",
     "iopub.status.busy": "2025-10-09T16:36:07.987020Z",
     "iopub.status.idle": "2025-10-09T16:36:07.990908Z",
     "shell.execute_reply": "2025-10-09T16:36:07.990459Z",
     "shell.execute_reply.started": "2025-10-09T16:36:07.987243Z"
    },
    "id": "db5aea5d-c673-48d6-876d-823f2e2e94d7",
    "outputId": "3880f805-6ef7-42c7-d10f-f01cc96c8d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Conv\n",
      "1: Conv\n",
      "2: C3k2\n",
      "3: Conv\n",
      "4: C3k2\n",
      "5: Conv\n",
      "6: C3k2\n",
      "7: Conv\n",
      "8: C3k2\n",
      "9: SPPF\n",
      "10: C2PSA\n",
      "11: Upsample\n",
      "12: Concat\n",
      "13: C3k2\n",
      "14: Upsample\n",
      "15: Concat\n",
      "16: C3k2\n",
      "17: Conv\n",
      "18: Concat\n",
      "19: C3k2\n",
      "20: Conv\n",
      "21: Concat\n",
      "22: C3k2\n",
      "23: Detect\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.model.model):\n",
    "    print(f\"{i}: {layer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ee9493-21bb-4511-a246-31bdbd68eba2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T20:34:53.200564Z",
     "iopub.status.busy": "2025-07-03T20:34:53.200339Z",
     "iopub.status.idle": "2025-07-03T20:34:53.204797Z",
     "shell.execute_reply": "2025-07-03T20:34:53.204260Z",
     "shell.execute_reply.started": "2025-07-03T20:34:53.200548Z"
    },
    "id": "35ee9493-21bb-4511-a246-31bdbd68eba2"
   },
   "source": [
    "Vediamo ora il **numero totale dei parametri**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "882759f0-8398-4096-b20c-7cb53ff7ef63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:09.550948Z",
     "iopub.status.busy": "2025-10-09T16:36:09.550761Z",
     "iopub.status.idle": "2025-10-09T16:36:09.556809Z",
     "shell.execute_reply": "2025-10-09T16:36:09.556246Z",
     "shell.execute_reply.started": "2025-10-09T16:36:09.550935Z"
    },
    "id": "882759f0-8398-4096-b20c-7cb53ff7ef63",
    "outputId": "78cedd5a-d51d-4ea8-ec37-c54606796ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale parametri: 20,114,688\n",
      "Parametri trainabili: 0\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Totale parametri: {total_params:,}\")\n",
    "print(f\"Parametri trainabili: {trainable_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14005f2e-10af-4deb-95fd-e62b1e4ec8fc",
   "metadata": {
    "id": "14005f2e-10af-4deb-95fd-e62b1e4ec8fc"
   },
   "source": [
    "I parametri trainabili sono 0 significa che il modello, allenato con PyTorch, è stato poi bloccato in modalità \"inference only\", cioè tutte le `requires_grad` sono state impostate a False. In altre parole, **questo modello può essere usato ma non riallenato**.\n",
    "\n",
    "Questo è perfettamente lecito se il modello viene:\n",
    "- caricato solo per inferenza (non per addestramento o fine-tuning),\n",
    "- esportato da un training precedente con `requires_grad=False`,\n",
    "- oppure se è stato congelato volutamente per risparmiare risorse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569c8782-a900-4265-b1e4-911695134f8b",
   "metadata": {
    "id": "569c8782-a900-4265-b1e4-911695134f8b"
   },
   "source": [
    "---\n",
    "L'elenco (ed il numero totale) delle **classi che il modello è in grado di riconoscere**.\n",
    "80 non è affatto male.\n",
    "C'è comunque sempre un trade-off: maggiore è il numero di classi riconoscibili dal modello, maggiore è anche la complessità computazionale.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eabac836-5377-4aa7-9d06-df2acccfe97c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:13.194701Z",
     "iopub.status.busy": "2025-10-09T16:36:13.194508Z",
     "iopub.status.idle": "2025-10-09T16:36:13.198566Z",
     "shell.execute_reply": "2025-10-09T16:36:13.198009Z",
     "shell.execute_reply.started": "2025-10-09T16:36:13.194687Z"
    },
    "id": "eabac836-5377-4aa7-9d06-df2acccfe97c",
    "outputId": "b84c6afa-e10f-4b6b-ba82-4cc45e147c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
      "Numero classi: 80\n"
     ]
    }
   ],
   "source": [
    "print(model.names)\n",
    "print(f\"Numero classi: {len(model.names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e945d3f-751a-4809-ba4d-5f7f3a93624b",
   "metadata": {
    "id": "1e945d3f-751a-4809-ba4d-5f7f3a93624b"
   },
   "source": [
    "Il file `yolo11m.pt` è un modello YOLOv8 **pre-addestrato sul dataset COCO** (Common Objects in Context).\n",
    "\n",
    "Cosa significa? **Rileva 80 classi**, che sono esattamente le classi ufficiali del dataset COCO.\n",
    "\n",
    "Questo modello non è personalizzato (cioè non è stato fine-tuned su un nostro dataset).\n",
    "\n",
    "È una copia rinominata di **yolov8m.pt** o **yolov8x.pt** (a seconda della dimensione).\n",
    "\n",
    "Qualche dettaglio extra:\n",
    "- Il dataset COCO è uno **standard per object detection**, contiene oggetti comuni: persone, animali, veicoli, oggetti domestici...\n",
    "- È il riferimento principale per il confronto tra modelli YOLO, SSD, Faster R-CNN, ecc.\n",
    "- I modelli preaddestrati su COCO sono molto efficaci out-of-the-box per **scene urbane, case, interni, ecc**. E quindi ideali per la video-sorveglianza, che è il nostro obiettivo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61524a49-a3d8-4b0a-8a9c-0e83a08a03f3",
   "metadata": {},
   "source": [
    "# L'allenamento di Yolo\n",
    "Un'idea intuitiva è data in [questo breve video](https://www.tiktok.com/@brainlink_project/video/7555861765465132310?_r=1&_t=ZN-90IxdCw2wzO) di *brainlink*.<br>\n",
    "Concetti: \n",
    "- funzione di perdita *J* (*loss function*), da minimizzare\n",
    "- *intersection over union*\n",
    "- le immagini di training sono corredate del \"vero\" *bounding box* (la *ground truth*) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b3832-db36-4d16-b8c0-8a1958c1d2eb",
   "metadata": {
    "id": "fc6b3832-db36-4d16-b8c0-8a1958c1d2eb"
   },
   "source": [
    "# Il caricamento del video (per Google Colab)\n",
    "\n",
    "Per prima cosa dobbiamo caricare nella **memoria di sessione** il video da rilevare.<br>\n",
    "\n",
    "*FARE l'upload del video nella memoria di sessione*\n",
    "\n",
    "Verifichiamone la presenza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vnYMpJ-YAutj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:18.468362Z",
     "iopub.status.busy": "2025-10-09T16:36:18.468147Z",
     "iopub.status.idle": "2025-10-09T16:36:18.752039Z",
     "shell.execute_reply": "2025-10-09T16:36:18.751363Z",
     "shell.execute_reply.started": "2025-10-09T16:36:18.468348Z"
    },
    "id": "vnYMpJ-YAutj",
    "outputId": "5380b391-1c6c-4b83-a25d-7750a7833d5f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Impossibile trovare il percorso specificato: '/content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m                        \u001b[38;5;66;03m# il package 'os' (che sta per operating system) fornisce una serie di funzioni per interagire con il sottostante sistema operativo\u001b[39;00m\n\u001b[0;32m      2\u001b[0m                                  \u001b[38;5;66;03m# il s.o. di una macchina virtuale di Google Colab è Linux\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Impossibile trovare il percorso specificato: '/content'"
     ]
    }
   ],
   "source": [
    "import os                        # il package 'os' (che sta per operating system) fornisce una serie di funzioni per interagire con il sottostante sistema operativo\n",
    "                                 # il s.o. di una macchina virtuale di Google Colab è Linux\n",
    "print(os.listdir('/content'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JGMsEyP4a0oe",
   "metadata": {
    "id": "JGMsEyP4a0oe"
   },
   "source": [
    "YOLO funziona meglio con video registrati **in formato orizzontale**. Se il video in input è stato registrato <u>in formato verticale (come il file `video_strada_2.mp4`)</u> lo possiamo **centrare** in formato orizzontale con \"padding\" nero intorno, con la libreria `ffmpeg`.\n",
    "\n",
    "La seguente cella mantiene il contenuto verticale intatto, ma lo centra in un video orizzontale.<br>\n",
    "Cosa fa esattamente?\n",
    "- `scale=-1:1080` → mantiene l’altezza a 1080, adatta la larghezza proporzionalmente\n",
    "- pad=1920:1080:(ow-iw)/2:(oh-ih)/2 → incornicia il video con bande nere per portarlo a 1920×1080 centrato\n",
    "\n",
    "Il parametro `-i` indica il file di input, il parametro `-vf` indica il tipo di \"video filter\" applicato (es. rotazioni, ridimensionamenti, sfocature, ecc.).\n",
    "\n",
    "Tempo di esecuzione: circa 2'.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "N73Ahn-ulSq6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T10:27:19.210494Z",
     "iopub.status.busy": "2025-10-09T10:27:19.210297Z",
     "iopub.status.idle": "2025-10-09T10:27:40.101675Z",
     "shell.execute_reply": "2025-10-09T10:27:40.101164Z",
     "shell.execute_reply.started": "2025-10-09T10:27:19.210479Z"
    },
    "id": "N73Ahn-ulSq6",
    "outputId": "2426c521-a018-4b04-df50-ac661ad961c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.0.1-essentials_build-www.gyan.dev Copyright (c) 2000-2024 the FFmpeg developers\n",
      "  built with gcc 13.2.0 (Rev5, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59.  8.100 / 59.  8.100\n",
      "  libavcodec     61.  3.100 / 61.  3.100\n",
      "  libavformat    61.  1.100 / 61.  1.100\n",
      "  libavdevice    61.  1.100 / 61.  1.100\n",
      "  libavfilter    10.  1.100 / 10.  1.100\n",
      "  libswscale      8.  1.100 /  8.  1.100\n",
      "  libswresample   5.  1.100 /  5.  1.100\n",
      "  libpostproc    58.  1.100 / 58.  1.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'video_strada.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    creation_time   : 2025-07-03T11:21:10.000000Z\n",
      "    com.android.version: 14\n",
      "    com.android.capture.fps: 30.000000\n",
      "  Duration: 00:00:31.79, start: 0.000000, bitrate: 17247 kb/s\n",
      "  Stream #0:0[0x1](eng): Video: h264 (High) (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080, 16987 kb/s, 30.01 fps, 30 tbr, 90k tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-07-03T11:21:10.000000Z\n",
      "        handler_name    : VideoHandle\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 256 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-07-03T11:21:10.000000Z\n",
      "        handler_name    : SoundHandle\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))\n",
      "  Stream #0:1 -> #0:1 (aac (native) -> aac (native))\n",
      "Press [q] to stop, [?] for help\n",
      "[libx264 @ 0000020da1ae0340] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2 AVX512\n",
      "[libx264 @ 0000020da1ae0340] profile High, level 4.0, 4:2:0, 8-bit\n",
      "[libx264 @ 0000020da1ae0340] 264 - core 164 r3191 4613ac3 - H.264/MPEG-4 AVC codec - Copyleft 2003-2024 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=18 lookahead_threads=3 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
      "Output #0, mp4, to 'video_strada_out.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : mp42\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isommp42\n",
      "    com.android.capture.fps: 30.000000\n",
      "    com.android.version: 14\n",
      "    encoder         : Lavf61.1.100\n",
      "  Stream #0:0(eng): Video: h264 (avc1 / 0x31637661), yuv420p(tv, bt709, progressive), 1920x1080, q=2-31, 30 fps, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-07-03T11:21:10.000000Z\n",
      "        handler_name    : VideoHandle\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 libx264\n",
      "      Side data:\n",
      "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
      "  Stream #0:1(eng): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 128 kb/s (default)\n",
      "      Metadata:\n",
      "        creation_time   : 2025-07-03T11:21:10.000000Z\n",
      "        handler_name    : SoundHandle\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.3.100 aac\n",
      "frame=    1 fps=0.0 q=29.0 size=       0KiB time=-00:00:00.03 bitrate=N/A speed=N/A    \n",
      "frame=   23 fps= 22 q=29.0 size=    1280KiB time=00:00:00.70 bitrate=14980.2kbits/s speed=0.682x    \n",
      "frame=   48 fps= 31 q=29.0 size=    2816KiB time=00:00:01.53 bitrate=15045.0kbits/s speed=0.997x    \n",
      "frame=   78 fps= 38 q=29.0 size=    4352KiB time=00:00:02.53 bitrate=14073.1kbits/s speed=1.23x    \n",
      "frame=  104 fps= 40 q=29.0 size=    5888KiB time=00:00:03.40 bitrate=14186.7kbits/s speed=1.32x    \n",
      "frame=  125 fps= 40 q=29.0 size=    6656KiB time=00:00:04.10 bitrate=13299.1kbits/s speed=1.33x    \n",
      "frame=  151 fps= 42 q=29.0 size=    7680KiB time=00:00:04.96 bitrate=12667.4kbits/s speed=1.38x    \n",
      "frame=  178 fps= 43 q=29.0 size=    8704KiB time=00:00:05.86 bitrate=12154.0kbits/s speed=1.42x    \n",
      "frame=  204 fps= 44 q=29.0 size=    9472KiB time=00:00:06.73 bitrate=11524.0kbits/s speed=1.45x    \n",
      "frame=  227 fps= 44 q=29.0 size=   10752KiB time=00:00:07.50 bitrate=11744.1kbits/s speed=1.45x    \n",
      "frame=  255 fps= 45 q=29.0 size=   11776KiB time=00:00:08.43 bitrate=11439.1kbits/s speed=1.48x    \n",
      "frame=  279 fps= 45 q=29.0 size=   12544KiB time=00:00:09.23 bitrate=11129.3kbits/s speed=1.49x    \n",
      "frame=  308 fps= 46 q=29.0 size=   13568KiB time=00:00:10.20 bitrate=10897.0kbits/s speed=1.51x    \n",
      "frame=  335 fps= 46 q=29.0 size=   14336KiB time=00:00:11.10 bitrate=10580.3kbits/s speed=1.53x    \n",
      "frame=  366 fps= 47 q=29.0 size=   15104KiB time=00:00:12.13 bitrate=10197.7kbits/s speed=1.56x    \n",
      "frame=  395 fps= 48 q=29.0 size=   16128KiB time=00:00:13.10 bitrate=10085.6kbits/s speed=1.58x    \n",
      "frame=  419 fps= 48 q=29.0 size=   16896KiB time=00:00:13.90 bitrate=9957.7kbits/s speed=1.58x    \n",
      "frame=  445 fps= 48 q=29.0 size=   17920KiB time=00:00:14.76 bitrate=9941.4kbits/s speed=1.59x    \n",
      "frame=  474 fps= 48 q=29.0 size=   19712KiB time=00:00:15.73 bitrate=10263.6kbits/s speed= 1.6x    \n",
      "frame=  496 fps= 48 q=29.0 size=   20736KiB time=00:00:16.46 bitrate=10316.0kbits/s speed=1.59x    \n",
      "frame=  524 fps= 48 q=29.0 size=   22528KiB time=00:00:17.40 bitrate=10606.3kbits/s speed= 1.6x    \n",
      "frame=  545 fps= 48 q=29.0 size=   23808KiB time=00:00:18.10 bitrate=10775.4kbits/s speed=1.59x    \n",
      "frame=  570 fps= 48 q=29.0 size=   25088KiB time=00:00:18.93 bitrate=10855.0kbits/s speed=1.59x    \n",
      "frame=  597 fps= 48 q=29.0 size=   27136KiB time=00:00:19.83 bitrate=11208.3kbits/s speed= 1.6x    \n",
      "frame=  621 fps= 48 q=29.0 size=   28928KiB time=00:00:20.63 bitrate=11485.2kbits/s speed=1.59x    \n",
      "frame=  648 fps= 48 q=29.0 size=   30720KiB time=00:00:21.53 bitrate=11686.9kbits/s speed= 1.6x    \n",
      "frame=  670 fps= 48 q=29.0 size=   32512KiB time=00:00:22.26 bitrate=11961.3kbits/s speed=1.59x    \n",
      "frame=  697 fps= 48 q=29.0 size=   34560KiB time=00:00:23.16 bitrate=12220.8kbits/s speed= 1.6x    \n",
      "frame=  718 fps= 48 q=29.0 size=   36096KiB time=00:00:23.86 bitrate=12389.6kbits/s speed=1.59x    \n",
      "frame=  727 fps= 47 q=29.0 size=   37376KiB time=00:00:24.16 bitrate=12669.7kbits/s speed=1.55x    \n",
      "frame=  742 fps= 46 q=29.0 size=   39680KiB time=00:00:24.66 bitrate=13178.1kbits/s speed=1.53x    \n",
      "frame=  755 fps= 45 q=29.0 size=   41216KiB time=00:00:25.10 bitrate=13451.9kbits/s speed=1.51x    \n",
      "frame=  772 fps= 45 q=29.0 size=   43264KiB time=00:00:25.66 bitrate=13808.5kbits/s speed= 1.5x    \n",
      "frame=  792 fps= 45 q=29.0 size=   44800KiB time=00:00:26.33 bitrate=13936.8kbits/s speed=1.49x    \n",
      "frame=  814 fps= 45 q=29.0 size=   46592KiB time=00:00:27.06 bitrate=14101.6kbits/s speed=1.49x    \n",
      "frame=  839 fps= 45 q=29.0 size=   47616KiB time=00:00:27.90 bitrate=13981.0kbits/s speed=1.49x    \n",
      "frame=  864 fps= 45 q=29.0 size=   48896KiB time=00:00:28.73 bitrate=13940.5kbits/s speed=1.49x    \n",
      "frame=  890 fps= 45 q=29.0 size=   49920KiB time=N/A bitrate=N/A speed=N/A    \n",
      "frame=  924 fps= 46 q=29.0 size=   50944KiB time=N/A bitrate=N/A speed=N/A    \n",
      "[out#0/mp4 @ 0000020da1a2c980] video:51451KiB audio:501KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.064162%\n",
      "frame=  954 fps= 46 q=-1.0 Lsize=   51985KiB time=00:00:31.73 bitrate=13420.0kbits/s speed=1.54x    \n",
      "[libx264 @ 0000020da1ae0340] frame I:5     Avg QP:24.77  size:199286\n",
      "[libx264 @ 0000020da1ae0340] frame P:519   Avg QP:26.74  size: 80100\n",
      "[libx264 @ 0000020da1ae0340] frame B:430   Avg QP:29.16  size: 23527\n",
      "[libx264 @ 0000020da1ae0340] consecutive B-frames: 35.7%  9.0% 10.4% 44.9%\n",
      "[libx264 @ 0000020da1ae0340] mb I  I16..4:  0.6% 85.8% 13.6%\n",
      "[libx264 @ 0000020da1ae0340] mb P  I16..4:  0.3% 11.6%  2.2%  P16..4: 46.4% 18.4% 11.4%  0.0%  0.0%    skip: 9.7%\n",
      "[libx264 @ 0000020da1ae0340] mb B  I16..4:  0.1%  1.5%  0.2%  B16..8: 45.4%  5.8%  1.2%  direct: 6.1%  skip:39.8%  L0:50.4% L1:40.4% BI: 9.2%\n",
      "[libx264 @ 0000020da1ae0340] 8x8 transform intra:82.9% inter:80.3%\n",
      "[libx264 @ 0000020da1ae0340] coded y,uvDC,uvAC intra: 91.6% 55.9% 16.5% inter: 41.4% 27.3% 3.3%\n",
      "[libx264 @ 0000020da1ae0340] i16 v,h,dc,p: 41% 22% 15% 21%\n",
      "[libx264 @ 0000020da1ae0340] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu: 16% 16% 14%  6% 10%  8% 13%  6% 11%\n",
      "[libx264 @ 0000020da1ae0340] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 17% 18%  9%  7% 12%  9% 14%  6%  9%\n",
      "[libx264 @ 0000020da1ae0340] i8c dc,h,v,p: 63% 20% 13%  4%\n",
      "[libx264 @ 0000020da1ae0340] Weighted P-Frames: Y:8.3% UV:2.7%\n",
      "[libx264 @ 0000020da1ae0340] ref P L0: 70.5% 17.0%  9.4%  2.9%  0.2%\n",
      "[libx264 @ 0000020da1ae0340] ref B L0: 94.4%  4.8%  0.8%\n",
      "[libx264 @ 0000020da1ae0340] ref B L1: 98.8%  1.2%\n",
      "[libx264 @ 0000020da1ae0340] kb/s:13254.05\n",
      "[aac @ 0000020da1a34140] Qavg: 621.773\n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i video_strada.mp4 -vf \"scale=-1:1080,pad=1920:1080:(ow-iw)/2:(oh-ih)/2\" video_strada_out.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeh1kYCPaZM6",
   "metadata": {
    "id": "aeh1kYCPaZM6"
   },
   "source": [
    "Eseguiamolo (20 secondi di caricamento):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1mYG_GwlaXrK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:32.351288Z",
     "iopub.status.busy": "2025-10-09T16:36:32.350864Z",
     "iopub.status.idle": "2025-10-09T16:36:32.354415Z",
     "shell.execute_reply": "2025-10-09T16:36:32.354018Z",
     "shell.execute_reply.started": "2025-10-09T16:36:32.351270Z"
    },
    "id": "1mYG_GwlaXrK",
    "outputId": "82f96094-57e9-4a80-985a-25c07f193c5d"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from IPython.display import Video, display\n",
    "    display(Video(\"/content/video_strada_2_landscape.mp4\", embed=True, width=640))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18lSHuz4m_zi",
   "metadata": {
    "id": "18lSHuz4m_zi"
   },
   "source": [
    "Il rendering precedente funziona con Chrome (browser e IDE dello **stesso ecosistema Google!**), ha problemi con Firefox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qKvFi_48Q4L2",
   "metadata": {
    "id": "qKvFi_48Q4L2"
   },
   "source": [
    "Possiamo preliminarmente fare **alcune analisi del nostro video <u>in input</u>**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb83ba56-5a35-4753-add5-37a55998e2ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T20:10:23.013974Z",
     "iopub.status.busy": "2025-07-03T20:10:23.013686Z",
     "iopub.status.idle": "2025-07-03T20:10:23.018684Z",
     "shell.execute_reply": "2025-07-03T20:10:23.018072Z",
     "shell.execute_reply.started": "2025-07-03T20:10:23.013955Z"
    },
    "id": "eb83ba56-5a35-4753-add5-37a55998e2ab"
   },
   "source": [
    "Per sapere il **numero di frame** del nostro video ed avere anche **altre informazioni** sul video stesso si usa il package `cv2`, il modulo Python di OpenCV (Open Source Computer Vision Library), e il metodo `VideoCapture`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5840f94a-e771-4819-aaad-39d028063e18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:48.818042Z",
     "iopub.status.busy": "2025-10-09T16:36:48.817853Z",
     "iopub.status.idle": "2025-10-09T16:36:48.845573Z",
     "shell.execute_reply": "2025-10-09T16:36:48.845130Z",
     "shell.execute_reply.started": "2025-10-09T16:36:48.818028Z"
    },
    "id": "5840f94a-e771-4819-aaad-39d028063e18",
    "outputId": "5faaf742-c1af-465b-a3ad-e4d9e093d5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero totale di frame: 954\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"video_strada_out.mp4\")\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "cap.release()\n",
    "\n",
    "print(f\"Numero totale di frame: {total_frames}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e28a0-638f-4fa8-ae92-ca11e92eb1b4",
   "metadata": {
    "id": "5c7e28a0-638f-4fa8-ae92-ca11e92eb1b4"
   },
   "source": [
    "Per avere altre informazioni:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba39783f-dbf4-4077-a32a-7eb5b2640c16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:36:52.029676Z",
     "iopub.status.busy": "2025-10-09T16:36:52.029476Z",
     "iopub.status.idle": "2025-10-09T16:36:52.052240Z",
     "shell.execute_reply": "2025-10-09T16:36:52.051865Z",
     "shell.execute_reply.started": "2025-10-09T16:36:52.029662Z"
    },
    "id": "ba39783f-dbf4-4077-a32a-7eb5b2640c16",
    "outputId": "24a539e9-998d-417e-f801-b8d872fff58f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risoluzione: 1920x1080\n",
      "FPS: 30.0\n",
      "Numero totale di frame: 954\n",
      "Durata del video: 31.80 secondi\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Apri il video\n",
    "cap = cv2.VideoCapture(\"video_strada_out.mp4\")\n",
    "\n",
    "# Estrai informazioni\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # frame per secondo\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # numero totale di frame\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # larghezza frame\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # altezza frame\n",
    "duration = frame_count / fps  # durata in secondi\n",
    "\n",
    "# Mostra le info\n",
    "print(f\"Risoluzione: {width}x{height}\")\n",
    "print(f\"FPS: {fps}\")\n",
    "print(f\"Numero totale di frame: {frame_count}\")\n",
    "print(f\"Durata del video: {duration:.2f} secondi\")\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bcb4ac7-5c0b-4d20-8ddf-2af1571d8482",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:37:10.233188Z",
     "iopub.status.busy": "2025-10-09T16:37:10.232990Z",
     "iopub.status.idle": "2025-10-09T16:37:10.237463Z",
     "shell.execute_reply": "2025-10-09T16:37:10.236899Z",
     "shell.execute_reply.started": "2025-10-09T16:37:10.233175Z"
    },
    "id": "6bcb4ac7-5c0b-4d20-8ddf-2af1571d8482",
    "outputId": "b1299d6a-8045-4d20-d945-bc01d356a1db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.774193548387096"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "954/31.00 # frame per second"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf7e39-d8ef-4ecd-b706-b35d71ad3a74",
   "metadata": {
    "id": "54bf7e39-d8ef-4ecd-b706-b35d71ad3a74"
   },
   "source": [
    "# Il rilevamento degli oggetti\n",
    "\n",
    "**<u>E ora finalmente facciamo il rilevamento degli oggetti</u>**, tramite il metodo `model.predict` di *Ultralytics*.\n",
    "\n",
    "L'elaborazione del file `video_strada_2.mp4` richiede:\n",
    "- **circa 3'30\"** sulla CPU 4Ghz, 16GB RAM del mio desktop\n",
    "- **circa 4'20\"** sulla T4-GPU con high-ram di Colab\n",
    "- **circa 6'20\"** sulla CPU di Colab\n",
    "\n",
    "NB. High RAM deselezionato **peggiora** molto questi tempi.\n",
    "\n",
    "Vedi più avanti per un commento tecnico a questi tempi di esecuzione.\n",
    "\n",
    "Il rilevamento oggetti tecnicamente parlando è una **previsione** di inboxing/classificazione di ogni cella della griglia, per ogni dataframe. E' una sola (YOLO v8 è one-shot). Da qui il nome del metodo di *Ultralytics* `(model.predict)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GjHujCkNdaf4",
   "metadata": {
    "id": "GjHujCkNdaf4"
   },
   "source": [
    "---\n",
    "> Nella AI questa si chiama **inferenza** (del modello allenato, cioè del **suo uso per prevedere/classificare/generare**).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c580eb4e-b5e2-450a-814d-861a7c613035",
   "metadata": {
    "id": "c580eb4e-b5e2-450a-814d-861a7c613035"
   },
   "source": [
    "I parametri della `model.predict`:\n",
    "- `source`:\n",
    "    * `source=0` per la webcam principale - in genere 0,1, oppure 2 (provare)\n",
    "    * `source=\"path/to/image.jpg\"` per un’immagine\n",
    "    * `source=\"path/to/video.mp4\"` per un video\n",
    "    * `source=\"rtsp://...\"` per uno stream IP\n",
    "- `device='cpu'`:\n",
    "    * usa la CPU per l’elaborazione.\n",
    "    * se si ha una GPU e si ha installato PyTorch con supporto CUDA, si può impostare `device='cuda'`.\n",
    "- `imgsz=640`:\n",
    "    * imposta la dimensione dei frame a 640×640 pixel.\n",
    "    * YOLOv8 lavora meglio se le immagini sono quadrate e di dimensioni standard (320, 640, 1280…).\n",
    "    * maggiore è il valore, più dettagli cattura (ma serve più potenza hardware).<br>\n",
    "    NB. il parametro imgsz` **si riferisce all’input**, ovvero alla dimensione con cui YOLOv8 ridimensiona ogni frame del video prima di passarlo alla rete neurale per il rilevamento oggetti.<br>\n",
    "    Cosa fa esattamente imgsz=640?<br>\n",
    "      - Ogni frame del video viene ridimensionato (resized) a una risoluzione di 640×640 pixel.\n",
    "      - Questo è il formato di input atteso dal modello per lavorare in modo ottimale.\n",
    "      - Non cambia la risoluzione originale del video, né influenza direttamente la risoluzione del video in output, che può rimanere uguale all’originale (a seconda del backend di salvataggio usato da Ultralytics).\n",
    "\n",
    "\n",
    "\n",
    "- `conf=0.1`:\n",
    "    * imposta la confidence threshold a 0.1.\n",
    "    * YOLO rileva oggetti solo se la probabilità della classe è superiore a questo valore.\n",
    "    * **di solito si imposta tra 0.25 e 0.5**, ma qui l'abbiamo messa bassa per “vedere tutto quello che il modello riesce a pescare” (le sue potenzialità).\n",
    "    * si è visto sperimentalmente che, con questa confidenza, YOLOv8 fa comunque pochi errori (mis-classificazioni)\n",
    "- `show=True`:\n",
    "    * mostra le immagini o i frame annotati in una finestra pop-up (usando `cv2.imshow`) in tempo reale; non funziona in Jupyter Notebook o Google Colab, **solo in ambienti standalone** (come Spyder, IDLE o script Python lanciati da terminale).\n",
    "- `stream=True`:\n",
    "    * se True, processa i frame in **streaming**; è utile nei notebook per evitare che vengano salvati tutti i frame nella variabile `results` (che occuperebbe tanta RAM).\n",
    "    * cioè, invece di restituire tutti i risultati in una lista in memoria (`results`), YOLOv8 ti restituisce un generatore, cioè un oggetto che produce i risultati uno alla volta, frame per frame.<br>\n",
    "    Questo:\n",
    "      - riduce il consumo di RAM\n",
    "      - è perfetto per video lunghi\n",
    "      - funziona benissimo anche con GPU\n",
    "\n",
    "\n",
    "- `save=True`:\n",
    "    * salva il video di output (annotato con bounding box, etichette di classe, confidenze) nella directory `runs/detect/predictN` di default. Il nome del file sarà simile al <nome-video.**mp4**> ma modificato come formato (es: <nome-video.**avi**>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y4lrdcV8OqyW",
   "metadata": {
    "id": "Y4lrdcV8OqyW"
   },
   "source": [
    "La `model.predict` PUO' essere assegnata ad una variabile di risultato, come detto prima e come fatto nella cella successiva (`results`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b736c8c-ffd0-407a-87ce-6f8fd03211d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-10-09T16:37:19.168924Z",
     "iopub.status.busy": "2025-10-09T16:37:19.168726Z"
    },
    "id": "7b736c8c-ffd0-407a-87ce-6f8fd03211d0",
    "outputId": "99640467-c062-47e9-b054-53118a74df97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 166.1ms\n",
      "video 1/1 (frame 2/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 persons, 2 cars, 140.4ms\n",
      "video 1/1 (frame 3/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 person, 2 cars, 150.8ms\n",
      "video 1/1 (frame 4/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 147.7ms\n",
      "video 1/1 (frame 5/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 149.6ms\n",
      "video 1/1 (frame 6/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 139.3ms\n",
      "video 1/1 (frame 7/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 151.6ms\n",
      "video 1/1 (frame 8/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 144.3ms\n",
      "video 1/1 (frame 9/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 142.7ms\n",
      "video 1/1 (frame 10/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 146.5ms\n",
      "video 1/1 (frame 11/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 149.4ms\n",
      "video 1/1 (frame 12/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 139.5ms\n",
      "video 1/1 (frame 13/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 142.4ms\n",
      "video 1/1 (frame 14/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 144.8ms\n",
      "video 1/1 (frame 15/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 147.9ms\n",
      "video 1/1 (frame 16/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 142.6ms\n",
      "video 1/1 (frame 17/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 142.3ms\n",
      "video 1/1 (frame 18/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 144.4ms\n",
      "video 1/1 (frame 19/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 144.7ms\n",
      "video 1/1 (frame 20/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 143.4ms\n",
      "video 1/1 (frame 21/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 153.9ms\n",
      "video 1/1 (frame 22/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 143.9ms\n",
      "video 1/1 (frame 23/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 146.4ms\n",
      "video 1/1 (frame 24/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 143.0ms\n",
      "video 1/1 (frame 25/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 (no detections), 146.1ms\n",
      "video 1/1 (frame 26/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 152.9ms\n",
      "video 1/1 (frame 27/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 151.9ms\n",
      "video 1/1 (frame 28/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 154.4ms\n",
      "video 1/1 (frame 29/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 2 cars, 147.6ms\n",
      "video 1/1 (frame 30/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 149.8ms\n",
      "video 1/1 (frame 31/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 149.0ms\n",
      "video 1/1 (frame 32/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 147.9ms\n",
      "video 1/1 (frame 33/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 151.9ms\n",
      "video 1/1 (frame 34/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 152.5ms\n",
      "video 1/1 (frame 35/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 150.5ms\n",
      "video 1/1 (frame 36/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 146.9ms\n",
      "video 1/1 (frame 37/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 143.9ms\n",
      "video 1/1 (frame 38/954) C:\\Users\\Utente\\Desktop\\salvataggi\\SALVATAGGIO DATI\\Documents\\Seminari\\Data Science (corsi)\\Corso Reti Neurali\\Computer Vision\\video_strada_out.mp4: 384x640 1 car, 146.5ms\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(\n",
    "    # source=0,\n",
    "    source='video_strada_out.mp4',\n",
    "    device='cpu',   # oppure 'gpu'\n",
    "    imgsz=640,\n",
    "    conf=0.1,\n",
    "    # show=True,\n",
    "    # stream = True,   # def. False\n",
    "    save=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1a7081-fc76-475a-904d-8ccc1f892ff3",
   "metadata": {
    "id": "1a1a7081-fc76-475a-904d-8ccc1f892ff3"
   },
   "source": [
    "Il codice di questa cella analizza il video frame per frame, rileva oggetti oppure no (\"no detections\") nei vari frame, salva il video **annotato (bounding box, etichette, confidenza**) nella sotto directory `runs/predict/predictN/`.\n",
    "\n",
    "`model.predict()` **termina automaticamente** quando ha processato tutti i frame del video.\n",
    "\n",
    "In questo caso:\n",
    "- il video ha 965 frame (lo si vede dal log)\n",
    "- YOLO elabora un frame alla volta\n",
    "- alla fine, salva il video elaborato nella cartella `runs/predict/predictX/`\n",
    "\n",
    "**Quanto ci mette?** Dipende da:\n",
    "- CPU (più lenta rispetto a una GPU)\n",
    "- Lunghezza del video (in secondi / numero di frame)\n",
    "- Risoluzione dei frame (imgsz=640)\n",
    "- Numero di oggetti rilevati per frame\n",
    "\n",
    "Con CPU su un video normale (1 minuto a 30 fps = ~1800 frame), può impiegare anche diversi minuti (es. 2–10 minuti).\n",
    "\n",
    "**Come sapere quando ha finito?**<br>\n",
    "Nel log c'è una riga senza più aggiornamento dei frame.<br>\n",
    "L’ultima riga dirà qualcosa tipo:<br>\n",
    "*Results saved to runs\\predict\\predict3*<br>\n",
    "Oppure:<br>\n",
    "*video 1/1 (frame 954/954) ... DONE (123.4ms)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8jKSiSgiESX7",
   "metadata": {
    "id": "8jKSiSgiESX7"
   },
   "source": [
    "---\n",
    "NB. A volte la GPU di Colab (anche la \"High-RAM\") può andare **più lenta della CPU locale del proprio PC!**\n",
    "\n",
    "🚦 MOTIVI PRINCIPALI\n",
    "1. Overhead del caricamento su GPU<br>\n",
    "Il video (.mp4) deve essere:\n",
    "  - letto da disco,\n",
    "  - decodificato in frame,\n",
    "  -convertito in tensori,\n",
    "  - spostato nella memoria della GPU (cuda).\n",
    "\n",
    "👉 Tutto questo richiede tempo e non è accelerato dalla GPU, quindi su video corti o piccoli il vantaggio della GPU non si vede (anzi: può peggiorare le performance).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MpdREoIfOV_n",
   "metadata": {
    "id": "MpdREoIfOV_n"
   },
   "source": [
    "# L'interpretazione dei risultati\n",
    "Il metodo `model.predict` fornisce tre output:\n",
    "- il log (in tempo reale)\n",
    "- il video annotato\n",
    "- i `results` su disco."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renW3elTLt13",
   "metadata": {
    "id": "renW3elTLt13"
   },
   "source": [
    "**Ma vediamo ora i contenuti della variabile `results`**:<br> è una lista di oggetti `ultralytics.engine.results.Results`, **uno per ogni frame** (o immagine, se l'input è un'immagine).\n",
    "\n",
    "Ogni oggetto contiene:\n",
    "- `.boxes` → le box previste\n",
    "- `.probs` → le probabilità (se classifica)\n",
    "- `.keypoints`, `.masks` → se si sono abilitate segmentazione o pose\n",
    "-`.plot()` → disegna le box su un’immagine\n",
    "- `.save()` → salva il frame annotato\n",
    "- `.orig_img` → immagine originale\n",
    "- `.names` → nomi delle classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5yF-Ll3R7g-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5yF-Ll3R7g-",
    "outputId": "08d3638f-373e-43da-8ecb-d3e93bc6466f"
   },
   "outputs": [],
   "source": [
    "type(results)   # una LISTA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bq8K6lXnScXt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bq8K6lXnScXt",
    "outputId": "d9519b43-3572-4295-c199-d0ac5c1bf0b6"
   },
   "outputs": [],
   "source": [
    "len(results)    # un elemento della lista per ogni frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZxWFhXrHR9pF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxWFhXrHR9pF",
    "outputId": "2add4631-fa15-4afb-ce37-182cd6ee2d69"
   },
   "outputs": [],
   "source": [
    "results[0]      # il primo frame (ottenuto tramite il subsetting di lista)\n",
    "                # molte info sono nel primo campo 'boxes': un oggetto ultralytics.engine.results.Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7n4HZGE6TeS1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "7n4HZGE6TeS1",
    "outputId": "48525bf7-bc95-4223-9414-82d81d47c41d"
   },
   "outputs": [],
   "source": [
    "type(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s0OGXMmWWncs",
   "metadata": {
    "id": "s0OGXMmWWncs"
   },
   "source": [
    "Estraiamo da `results` le classi individuate nel primo frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jU37ZQo7UQo0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jU37ZQo7UQo0",
    "outputId": "7faa9938-a0d3-48ba-c541-b0c951557d82"
   },
   "outputs": [],
   "source": [
    "results[1].boxes.cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q4iutdDNMfgo",
   "metadata": {
    "id": "Q4iutdDNMfgo"
   },
   "source": [
    "2 è la classe *cars*, 0 è la classe *person*, 3 è la classe *motorcycle* - vedi log precedente.\n",
    "\n",
    "Ora estraiamo da `results` le probabilità (**confidence**) delle classi individuate (nel primo frame):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da-atNLjVVWs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da-atNLjVVWs",
    "outputId": "9a68a31a-5b40-40e3-a230-09369e5ada06"
   },
   "outputs": [],
   "source": [
    "results[1].boxes.conf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FW97Wk0eQ_FK",
   "metadata": {
    "id": "FW97Wk0eQ_FK"
   },
   "source": [
    "Nessuna classe rilevata ha confidenza inferiore al valore 0.10, che infatti avevamo impostato nella `model.predict` come valore soglia limite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C0drp6PVVRmd",
   "metadata": {
    "id": "C0drp6PVVRmd"
   },
   "source": [
    "Esempio strutturato: stampare le classi rilevate per i primi 5 frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i2Wa0_D9Mluo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2Wa0_D9Mluo",
    "outputId": "104a9d14-8ead-4ca0-f3eb-34605e6c64ff"
   },
   "outputs": [],
   "source": [
    "for r in results[:5]:\n",
    "    print([r.names[int(cls)] for cls in r.boxes.cls])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9I3p_M3cRqiS",
   "metadata": {
    "id": "9I3p_M3cRqiS"
   },
   "source": [
    "Il video in oggetto è affollato da macchine parcheggiate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Aleh5e-tV0Jj",
   "metadata": {
    "id": "Aleh5e-tV0Jj"
   },
   "source": [
    "Esempio strutturato: stampare le probabilità  delle classi rilevate per i primi 5 frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p3PX5BK4WAgU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3PX5BK4WAgU",
    "outputId": "74c3ac77-9f26-4b7d-aa57-59317469fa32"
   },
   "outputs": [],
   "source": [
    "for i, r in enumerate(results[:5]):\n",
    "    print(f\"\\n Frame {i+1}\")\n",
    "    boxes = r.boxes\n",
    "    for j in range(len(boxes)):\n",
    "        cls_id = int(boxes.cls[j])         # ID classe predetta\n",
    "        cls_name = r.names[cls_id]         # nome della classe\n",
    "        conf = float(boxes.conf[j])        # confidenza\n",
    "        print(f\" - {cls_name:15s} conf: {conf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FsD_-zwPHSmY",
   "metadata": {
    "id": "FsD_-zwPHSmY"
   },
   "source": [
    "---\n",
    "> Oltre alla variabile `results` (ed al log), la `model.predict()` di YOLOv8 (*Ultralytics*) restituisce in output il file `.avi` annotato (**vedi la cartella sottostante (Windows o Linux)**.\n",
    "\n",
    "> Il file non è in formato `.mp4` per **scelta tecnica predefinita** della libreria, che usa `OpenCV (cv2)` per salvare i video.\n",
    "\n",
    "> Secondo chatGPT, il formato `.avi` è ottimo per:\n",
    "- analisi video con modelli ML\t- AVI (meno compressione → meno perdita info)\n",
    "- montaggio video con poco decoding\tAVI\n",
    "\n",
    "\n",
    "> Tuttavia, il formato `.avi` non è <u>sempre</u> ben supportato nei browser. Si deve **convertire** in `.mp4` con la famosa libreria [`ffmpeg`](https://en.wikipedia.org/wiki/FFmpeg) (qualche minuto).\n",
    "\n",
    "> Attenzione: l'output `.mp4` deve essere salvato anch'esso nella sotto-directory `runs/detect/predict` per non sovrascrivere l'originale!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dNwlBURHH6ZY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dNwlBURHH6ZY",
    "outputId": "29265e0c-3cef-46f3-8e9e-7c116f1094d6"
   },
   "outputs": [],
   "source": [
    "!ffmpeg -i runs/detect/predict2/video_strada_2_landscape.avi -vcodec libx264 -crf 23 runs/detect/predict2/video_strada_2_landscape.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mZyzuxizGgDb",
   "metadata": {
    "id": "mZyzuxizGgDb"
   },
   "source": [
    "# L'esecuzione del file\n",
    "\n",
    "Eseguiamo il file.\n",
    "\n",
    "In <u>Jupyter Notebook su Windows</u> è sufficiente fare **doppio click** sul file prodotto nella directory `run/detect/predictN`.\n",
    "\n",
    "In <u>Google Colab su Linux</u> non si può eseguire il video con doppio click, perché non è un ambiente desktop. Però si può visualizzarlo dentro il notebook in questo semplice modo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HpKl24TVZvx1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "HpKl24TVZvx1",
    "outputId": "4777c05a-39bc-4481-8e39-c6106b4734df"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "  from IPython.display import Video\n",
    "  display(Video(\"/content/runs/detect/predict2/video_strada_2_landscape.mp4\", embed=True, width=640))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nysoYvy5E-aO",
   "metadata": {
    "id": "nysoYvy5E-aO"
   },
   "source": [
    "Con lo stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pVPBBKLJdBuZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "pVPBBKLJdBuZ",
    "outputId": "3b0a5c48-429f-4f9b-9f8d-c5825faccc06"
   },
   "outputs": [],
   "source": [
    "results = model.predict(source='video_strada_2.mp4', stream=True)\n",
    "for r in results:\n",
    "    print(r.boxes)  # stampa le box del frame corrente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6746af-648b-41c2-aaff-76acaccbad28",
   "metadata": {
    "id": "ef6746af-648b-41c2-aaff-76acaccbad28"
   },
   "source": [
    "# Script standalone\n",
    "Ecco una **versione interattiva** del codice precedente pensata per essere eseguita in uno script Python standalone (**non in Jupyter, ma da shell**), in modo che venga mostrato **in tempo reale** il video con i bounding box rilevati da YOLOv8:\n",
    "\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "model = YOLO(\"yolo11m.pt\")\n",
    "model.predict(\n",
    "    source=\"video_strada.mp4\",  \n",
    "    device='cpu',              \n",
    "    imgsz=640,\n",
    "    conf=0.3,                \n",
    "    show=True,                  \n",
    "    stream=False,              \n",
    "    save=False                 \n",
    ")\n",
    "```\n",
    "**Note**:<br>\n",
    "- `show=True` funziona solo fuori da Jupyter (es. lanciando da terminale: *python yolo_video.py*)\n",
    "- si può usare `source=0` per la webcam live\n",
    "- se si vuole anche salvare il video annotato, impostare `save=True`\n",
    "- `stream=False` va bene se il video è corto; se è lungo, si può impostare `stream=True` per evitare uso eccessivo di RAM\n",
    "\n",
    "---\n",
    "Il file **script_standalone.py** contiene il codice per la shell mostrato in questa cella; eseguirlo in questo modo:\n",
    "- attivare un prompt anaconda\n",
    "- attivare l'ambiente *myenv* (dove questo notebook ha fatto le installazioni dei package)\n",
    "- posizionarsi nella directory corrente di questo notebook con:<br>\n",
    "*cd C:/Users/Utente/Desktop/salvataggi/SALVATAGGIO DATI/Documents/Seminari/Data Science (corsi)/Corso Reti Neurali/Computer Vision*\n",
    "- eseguire `python script_standalone.py`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd255fdd-8ad9-4363-954e-d8defb69f4c3",
   "metadata": {
    "id": "fd255fdd-8ad9-4363-954e-d8defb69f4c3"
   },
   "source": [
    "Qui un [utile video](https://docs.ultralytics.com/modes/predict/#introduction) sulla estrazione dei risultati dell'inferenza."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8d4308-9981-41ee-93c3-1654617d6769",
   "metadata": {
    "id": "4f8d4308-9981-41ee-93c3-1654617d6769"
   },
   "source": [
    "# YOLO vs OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ca3962-2292-4269-a491-37aad041c0b7",
   "metadata": {
    "id": "a5ca3962-2292-4269-a491-37aad041c0b7"
   },
   "source": [
    "OpenCV e YOLO sono due pilastri nel mondo della Computer Vision, ma **servono a scopi diversi** (anche se possono essere usati insieme). Vediamo le differenze con vari punti chiave e poi qualche esempio d’uso.\n",
    "\n",
    "**1. Cos'è OpenCV?**\n",
    "OpenCV (Open Source Computer Vision Library) è una libreria generalista per la computer vision.\n",
    "\n",
    "È scritta in C/C++ ma ha binding per Python, Java, ecc.\n",
    "\n",
    "Serve per elaborazione di immagini e video: **filtri, segmentazione, morphing, motion tracking, ecc**.\n",
    "\n",
    "Contiene algoritmi tradizionali di visione artificiale (no AI): ad esempio, edge detection, template matching, optical flow, ecc.\n",
    "\n",
    "Ha anche moduli per machine learning, ma non nasce per le reti neurali.\n",
    "\n",
    "**Esempi di cosa puoi fare con OpenCV**:\n",
    "\n",
    "Rilevare un volto con Haar Cascade\n",
    "\n",
    "Trovare contorni in un’immagine\n",
    "\n",
    "Applicare filtri, trasformazioni geometriche\n",
    "\n",
    "Lavorare con videocamere\n",
    "\n",
    "**Cos'è YOLO?**\n",
    "\n",
    "YOLO (You Only Look Once) è un **algoritmo di object detection basato su deep learning**, ovvero:\n",
    "\n",
    "Usa una rete neurale convoluzionale (CNN)\n",
    "\n",
    "Rileva e **classifica oggetti** in un’immagine o un video in tempo reale (frame per frame)\n",
    "\n",
    "Ti restituisce bounding box, label, confidenza\n",
    "\n",
    "Le versioni recenti (YOLOv5, v7, v8, v9) sono super veloci ed efficienti, anche su mobile e CPU.\n",
    "\n",
    "**Esempi di cosa fa YOLO**:\n",
    "\n",
    "In un video di traffico: individua auto, persone, semafori, moto\n",
    "\n",
    "In uno stadio: individua giocatori, palloni, arbitri\n",
    "\n",
    "In un magazzino: rileva scatole, prodotti, pallet\n",
    "\n",
    "Inoltre registra gli oggetti rilevati.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbade3-1b50-418d-a9e1-70ab6d75746f",
   "metadata": {
    "id": "6edbade3-1b50-418d-a9e1-70ab6d75746f"
   },
   "source": [
    "---\n",
    "**Video sorveglianza di giardini, case, stanze, ecc tramite webcam.**<br>\n",
    "In tempo reale e gratuitamente.<br>\n",
    "Produzione di statistiche sugli oggetti / persone / animali rilevati.<br>\n",
    "Alert via email con frame allegato, per valutare se il positivo è vero o falso (l'11 luglio).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ed042-a05b-47d1-8140-72872e9eb666",
   "metadata": {
    "id": "984ed042-a05b-47d1-8140-72872e9eb666"
   },
   "source": [
    "# Generatori di codice: esercizio\n",
    "\n",
    "E' possibile avere una barra di avanzamento della `model.predict`?<br>\n",
    "Chiedere a chatGPT o Claude.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c4beb-7f99-4cf7-aabe-9810ee2e65f7",
   "metadata": {},
   "source": [
    "# Versione 2: email di warning\n",
    "Facciamo un miglioramento al nostro sistema di video-sorveglianza.<br>\n",
    "Quando nel campo visivo della webcam compare una persona il sistema in automatico invia una email con quel frame. E' importante per riconoscere i falsi positivi.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4541be88-9d6e-4e5a-aaad-8d990a34e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import requests\n",
    "import cv2\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef192ce-4690-4027-8cd9-9e3d7944506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserire la URL di Zapier\n",
    "URL_WEBHOOK = \"https://hooks.zapier.com/hooks/catch/23724713/u3l6nas/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22af98bd-36dd-403f-8615-331e5f8a1163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il modello\n",
    "modello = YOLO(\"yolo11m.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765edf33-9b46-4ab3-ac92-5a529c531f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result in modello.predict(\n",
    "    source='video_strada_2.mp4',\n",
    "    device='cpu',\n",
    "    imgsz=640,\n",
    "    conf=0.1,\n",
    "    # stream=True,    # streaming frame-by-frame\n",
    "    show=True       # mantiene la visualizzazione live\n",
    "):\n",
    "    # Classi rilevate nel frame\n",
    "    id_classi = result.boxes.cls.cpu().numpy().astype(int)\n",
    " \n",
    "    # Se c'è almeno una persona (classe 0)\n",
    "    if 0 in id_classi:\n",
    "        ora_corrente = datetime.now()\n",
    "        # Controlla se è passato abbastanza tempo dall'ultimo invio\n",
    "        if ultimo_invio is None or ora_corrente - ultimo_invio >= pausa_di_attesa:\n",
    "            # Prepara il frame annotato\n",
    "            frame = result.plot()  # numpy array BGR\n",
    "            success, buffer = cv2.imencode('.jpg', frame)\n",
    "            if not success:\n",
    "                continue\n",
    " \n",
    "            # Pre‐formatting del timestamp: HH:mm D/M/YY\n",
    "            day   = ora_corrente.day\n",
    "            month = ora_corrente.month\n",
    "            year2 = ora_corrente.year % 100\n",
    "            # es. \"10:09 23/6/25\"\n",
    "            formatted_timestamp = ora_corrente.strftime(\"%H:%M \") + f\"{day}/{month}/{year2:02}\"\n",
    " \n",
    "            # Payload testuale\n",
    "            data = {\n",
    "                \"event\":     \"person_detected\",\n",
    "                \"count\":     int((id_classi == 0).sum()),\n",
    "                \"timestamp\": formatted_timestamp\n",
    "            }\n",
    "            # File binary\n",
    "            files = {\n",
    "                \"file\": (\"frame.jpg\", buffer.tobytes(), \"image/jpeg\")\n",
    "            }\n",
    " \n",
    "            try:\n",
    "                requests.post(URL_WEBHOOK, data=data, files=files, timeout=5).raise_for_status()\n",
    "                print(f\"[{formatted_timestamp}] Webhook inviato con frame allegato\")\n",
    "                ultimo_invio = ora_corrente\n",
    "            except requests.RequestException as errore:\n",
    "                print(\"Errore invio webhook:\", errore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7209a8-0f33-49f9-b8b2-78d8217917aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
